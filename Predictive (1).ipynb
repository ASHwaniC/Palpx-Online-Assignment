{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read all the csv files\n",
    "files1=pd.read_csv('Consulting 1.csv',encoding = \"ISO-8859-1\")\n",
    "files2=pd.read_csv('Consulting 2.csv',encoding = \"ISO-8859-1\")\n",
    "files3=pd.read_csv('Consulting 3.csv')\n",
    "files4=pd.read_csv('Consulting 4.csv',encoding = \"ISO-8859-1\")\n",
    "files5=pd.read_csv('Consulting 5.csv')\n",
    "files6=pd.read_csv('Consulting 6.csv')\n",
    "files7=pd.read_csv('Consulting 7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3059, 59)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select only the rows in files1 who had completed application\n",
    "files1= files1.loc[files1['completedapplication']==1]\n",
    "files1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge all the files in 1 on the basis of candidateid\n",
    "result0 = pd.merge(files1,files6, on='candidateid',how='left')\n",
    "result00 = pd.merge(result0,files7, on='jobcandidate',how='left')\n",
    "result = pd.merge(result00,files5, on='candidateid',how='left')\n",
    "# result is the final merged file\n",
    "#result2=pd.merge(files1,files4, on='candidateid', how='left')\n",
    "files2=pd.merge(files1,files2, on='candidateid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#delete the columns from files3\n",
    "files3= files3.drop('createDate',axis=1)\n",
    "files3= files3.drop('createBy',axis=1)\n",
    "files3= files3.drop('modifyDate',axis=1)\n",
    "files3= files3.drop('modifyBy',axis=1)\n",
    "files3= files3.drop('id',axis=1)\n",
    "files3= files3.drop('score1',axis=1)\n",
    "files3= files3.drop('score2',axis=1)\n",
    "files3= files3.drop('score3',axis=1)\n",
    "files3= files3.drop('score4',axis=1)\n",
    "files3= files3.drop('Unnamed: 0',axis=1)\n",
    "# rename the column userid with candidateid\n",
    "files3= files3.rename(columns={'userid':'candidateid'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transforming the files3 dataset\n",
    "df1=files3.pivot_table(index='candidateid', columns='dimensiontype', values='finalscore')\n",
    "df1new = pd.DataFrame(df1.to_records())\n",
    "#merging new dataframe with the result file\n",
    "df2=pd.merge(result,df1new,on='candidateid',how='left')\n",
    "#Creating dummies for each applicant source\n",
    "df2new=pd.get_dummies(df2['source'])\n",
    "#updating the dataframe with the new one\n",
    "df2=pd.concat([df2, df2new], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Droping the columns from df2 we don't need\n",
    "df2=df2.drop('Unnamed: 0', axis=1)\n",
    "df2=df2.drop('candidateid', axis=1)\n",
    "df2=df2.drop('jobstatus', axis=1)\n",
    "df2=df2.drop('source', axis=1)\n",
    "df2=df2.drop('Applicant_type', axis=1)\n",
    "df2=df2.drop('AllApplicants', axis=1)\n",
    "df2=df2.drop('NewApplicant', axis=1)\n",
    "df2=df2.drop('AccountCreated', axis=1)\n",
    "df2=df2.drop('SQCompleted', axis=1)\n",
    "df2=df2.drop('ScreeningPass', axis=1)\n",
    "df2=df2.drop('completedapplication', axis=1)\n",
    "df2=df2.drop('newaddress', axis=1)\n",
    "df2=df2.drop('targetIndustry', axis=1)\n",
    "df2=df2.drop('targetFunction', axis=1)\n",
    "df2=df2.drop('assessments_taken', axis=1)\n",
    "df2=df2.drop('total_assessments', axis=1)\n",
    "df2=df2.drop('ass_compl_rate', axis=1)\n",
    "df2=df2.drop('newjoblocation', axis=1)\n",
    "df2=df2.drop('domain', axis=1)\n",
    "df2=df2.drop('jobRegion', axis=1)\n",
    "df2=df2.drop('industry', axis=1)\n",
    "df2=df2.drop('companyname', axis=1)\n",
    "df2=df2.drop('employeeCount', axis=1)\n",
    "df2=df2.drop('Companyage', axis=1)\n",
    "df2=df2.drop('ShortQScore', axis=1)\n",
    "df2=df2.drop('jobOpeningStatus', axis=1)\n",
    "df2=df2.drop('outreachcall', axis=1)\n",
    "df2=df2.drop('SQanswered', axis=1)\n",
    "df2=df2.drop('engagementtime', axis=1)\n",
    "df2=df2.drop('voice_int_status', axis=1)\n",
    "df2=df2.drop('voice_mandatory', axis=1)\n",
    "df2=df2.drop('YearMonthApplied', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Converting the assessments_mandatory column in 1 or 0\n",
    "df2.ix[df2.assessments_mandatory == 'YES', 'assessments_mandatory'] = 1\n",
    "df2.ix[df2.assessments_mandatory == 'NO', 'assessments_mandatory'] = 0\n",
    "#Converting the willingtoRelocate column in 1 or 0\n",
    "df2.willingtoRelocate=df2.willingtoRelocate.str.replace('Yes','1')\n",
    "df2.willingtoRelocate=df2.willingtoRelocate.str.replace('No','0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import re\n",
    "import string\n",
    "punch=set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Selecting the column on which we need to cluster the Dataframe\n",
    "x=df2['degree']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for cleaning the text\n",
    "def clean(text):\n",
    "    text=text.lower()\n",
    "    text=re.sub(r'[^a-zA-Z]',\" \",text)\n",
    "    text=\"\".join([i for i in text if i not in punch])\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using Tfidf Vectorizer to Vectorize the target column\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=1.0,\n",
    "                             min_df=0.0,\n",
    "                             tokenizer=clean,\n",
    "                             lowercase=False)\n",
    "Tfidf_matrix = vectorizer.fit_transform(x.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   3.19967630e-02,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   6.07903743e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   7.46343197e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   3.19242105e-02,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "       [  2.87360465e-02,   6.67711786e-04,   6.61000944e-03,\n",
       "          3.92437851e-04,   1.95212943e-03,   5.38088930e-04,\n",
       "          3.36496349e-04,   6.39428719e-04,   1.27170648e-03,\n",
       "          3.33294231e-03,   4.80876076e-04,   1.88857413e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   5.08499253e-04,\n",
       "          1.39873240e-04,   2.99849972e-03,   5.50442915e-04,\n",
       "          9.94168081e-04,   7.54975058e-04,   9.44287063e-04,\n",
       "          3.77714825e-03,   9.44287063e-04,   6.90333917e-04,\n",
       "          9.44287063e-04,   4.26819925e-04,   9.44287063e-04,\n",
       "          1.03871577e-02,   4.56577940e-04,   1.88857413e-03,\n",
       "          4.26819925e-04,   5.79460137e-03,   1.85938241e-02,\n",
       "          0.00000000e+00,   0.00000000e+00,   5.17829767e-03,\n",
       "          8.08881366e-04,   3.03717652e-04,   2.40225135e-03,\n",
       "          6.67711786e-04,   5.50442915e-04,   9.26628298e-04,\n",
       "          0.00000000e+00,   5.60273934e-04,   1.33542357e-03,\n",
       "          3.30275964e-03,   5.61358429e-04,   7.05356485e-04,\n",
       "          4.38213822e-04,   5.35827918e-04,   0.00000000e+00,\n",
       "          4.23873358e-04,   5.69777920e-04,   6.36473430e-04,\n",
       "          6.66793055e-04,   8.37344154e-04,   3.77901893e-02,\n",
       "          8.53315853e-03,   0.00000000e+00,   4.25951201e-03,\n",
       "          3.39828454e-03,   8.45198987e-04,   4.82563126e-04,\n",
       "          2.39749913e-03,   0.00000000e+00,   2.95618466e-04,\n",
       "          5.17048366e-04,   3.49054518e-04,   3.34554578e-01,\n",
       "          0.00000000e+00,   1.31004369e-03,   3.07779841e-04,\n",
       "          3.07779841e-04,   7.83988922e-03,   1.37173744e-03,\n",
       "          3.07779841e-04,   3.07779841e-04,   4.18791911e-04,\n",
       "          1.04361103e-03,   6.03603636e-03,   3.03717652e-04,\n",
       "          6.84096108e-03,   1.27170648e-03,   5.64426111e-04,\n",
       "          3.49054518e-04,   7.05418766e-04,   2.95618466e-04,\n",
       "          1.62516966e-03,   5.30803054e-04,   0.00000000e+00,\n",
       "          0.00000000e+00,   3.36496349e-04,   9.44287063e-04,\n",
       "          1.33542357e-03,   2.95618466e-04,   4.18791911e-04,\n",
       "          0.00000000e+00,   3.03717652e-04,   4.38213822e-04,\n",
       "          1.06871900e-03,   1.31490953e-02,   4.23873358e-04,\n",
       "          4.38213822e-04,   5.05276725e-04,   3.03717652e-04,\n",
       "          0.00000000e+00,   1.55353229e-03,   3.78019752e-03,\n",
       "          4.37312289e-04,   2.95618466e-04,   0.00000000e+00,\n",
       "          4.79554862e-04,   3.36496349e-04,   9.33870192e-04,\n",
       "          3.03717652e-04,   5.60273934e-04,   3.77714825e-03,\n",
       "          1.88857413e-03,   7.80656025e-02,   3.80054241e-03,\n",
       "          6.94112365e-03,   3.02545808e-03,   0.00000000e+00,\n",
       "          4.47561309e-03,   2.94810461e-03,   2.03293958e-01,\n",
       "          2.83286119e-03,   6.61000944e-03,   5.59174714e-04,\n",
       "          9.44287063e-04,   6.24352028e-04,   0.00000000e+00,\n",
       "          1.25206085e-03,   9.44287063e-04,   6.66073705e-03,\n",
       "          7.11096948e-03,   5.66572238e-03,   9.44287063e-04,\n",
       "          7.36543909e-02,   5.56547944e-04,   0.00000000e+00,\n",
       "          2.95618466e-04,   3.92437851e-04,   5.45184390e-04,\n",
       "          5.06497845e-03,   4.80876076e-04,   2.86159609e-03,\n",
       "          3.35727917e-01,   3.33769609e-02,   3.49054518e-04,\n",
       "          7.36383811e-04,   3.65176822e-02,   1.35865194e-03,\n",
       "          3.59580877e-03,   9.44287063e-04,   9.92638846e-04,\n",
       "          1.07221198e-02,   1.23709342e-03,   2.37522722e-03,\n",
       "          9.05492036e-04,   1.37224620e-02,   3.92437851e-04,\n",
       "          5.58816642e-04,   1.11469815e-03,   2.95618466e-04,\n",
       "          1.09027434e-03,   1.15512939e-03,   6.52706683e-04,\n",
       "          6.12638924e-03,   3.07779841e-04,   5.45184390e-04,\n",
       "          2.84680120e-03,   3.03717652e-04,   2.07332690e-03,\n",
       "          3.91322285e-04,   3.07779841e-04,   1.06212679e-03,\n",
       "          3.07779841e-04,   4.23873358e-04,   2.33207469e-03,\n",
       "          3.36496349e-04,   3.61582779e-02,   3.20601304e-03,\n",
       "          4.52414650e-03,   1.16379561e-03,   4.23873358e-04,\n",
       "          2.95618466e-04,   5.97508233e-04,   1.24616924e-03,\n",
       "          5.24616074e-04,   6.38683444e-04,   1.30496519e-03,\n",
       "          6.38683444e-04,   5.00602947e-04,   5.06480713e-03,\n",
       "          0.00000000e+00,   6.23065067e-04,   6.41308476e-03,\n",
       "          5.45184390e-04,   2.95618466e-04,   2.42965148e-02,\n",
       "          8.51800117e-04,   3.36496349e-04,   4.37312289e-04,\n",
       "          0.00000000e+00,   9.61013118e-04,   4.79554862e-04,\n",
       "          2.95618466e-04,   2.92806352e-04,   4.56577940e-04],\n",
       "       [  2.92270472e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.43605469e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.39641873e-03,   4.11623458e-02,   0.00000000e+00,\n",
       "          5.40311410e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "          8.03102390e-04,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   2.64059826e-02,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.39641873e-03,   9.28554892e-04,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          8.86452263e-04,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.22067617e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.61940991e-03,   1.11382887e-01,\n",
       "          0.00000000e+00,   0.00000000e+00,   5.10126367e-04,\n",
       "          0.00000000e+00,   0.00000000e+00,   5.63064625e-04,\n",
       "          0.00000000e+00,   5.56400968e-04,   2.05801295e-01,\n",
       "          8.18749185e-04,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.20285560e-03,   9.38462135e-04,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.30097900e-01,   8.68731742e-04,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   8.68731742e-04,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          8.47379936e-04,   2.11609818e-02,   0.00000000e+00,\n",
       "          7.12388825e-04,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.01469673e-03,\n",
       "          9.38462135e-04,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          9.28554892e-04,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   3.30400362e-03,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          8.75953442e-04,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.16815729e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.77206728e-04,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   9.28554892e-04,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.11949478e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   5.56400968e-04,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.11623458e-02,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.35772867e-02,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          7.25414537e-04,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          8.94864241e-04,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   4.12408486e-02,   0.00000000e+00,\n",
       "          2.20868560e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   2.67429077e-01,\n",
       "          1.30769466e-01,   0.00000000e+00,   2.11129994e-02,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.31170856e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "          5.56400968e-04,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   5.29332062e-04,   0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.77262059e-03,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.85534858e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   4.43381549e-03,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   9.90300307e-01,   1.66949385e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.57060013e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.41592325e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.54434732e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clustering using KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=4,\n",
    "               max_iter=300,\n",
    "               tol=0.001,\n",
    "               algorithm='auto')\n",
    "model.fit(Tfidf_matrix)\n",
    "labels = model.predict(Tfidf_matrix)\n",
    "model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making a different column for Degree using the clustering result\n",
    "df2['Degree']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Selecting the column on which we need to cluster the Dataframe\n",
    "x=df2['currentJobTitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using Tfidf Vectorizer to Vectorize the target column\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=1.0,\n",
    "                             min_df=0.0,\n",
    "                             tokenizer=clean,\n",
    "                             lowercase=False)\n",
    "Tfidf_matrix = vectorizer.fit_transform(x.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0012147 ,  0.00110037,  0.0008806 , ...,  0.00057243,\n",
       "         0.00038514,  0.0032567 ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clustering using KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=6,\n",
    "               max_iter=300,\n",
    "               tol=0.001,\n",
    "               algorithm='auto')\n",
    "model.fit(Tfidf_matrix)\n",
    "labels = model.predict(Tfidf_matrix)\n",
    "model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making a different column for Degree using the clustering results\n",
    "df2['JobTitle']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A different column using the ratio for Experience\n",
    "df2['ratiominexp']=df2['totalExperience']/df2['minimumExp']\n",
    "df2['ratiomaxexp']=df2['totalExperience']/df2['maximumExp']\n",
    "#A different column using the ratio for Salary\n",
    "df2['ratiominsalary']=df2['expectedAnnualSalary']/df2['minAnnualSalary']\n",
    "df2['ratiomaxsalary']=df2['expectedAnnualSalary']/df2['maxAnnualSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dropping the columns from df2 \n",
    "df2=df2.drop('currentJobTitle', axis=1)\n",
    "df2=df2.drop('currentEmployer', axis=1)\n",
    "df2=df2.drop('currentJobStatus', axis=1)\n",
    "df2=df2.drop('currentAnnualSalary', axis=1)\n",
    "df2=df2.drop('expectedAnnualSalary', axis=1)\n",
    "df2=df2.drop('currency', axis=1)\n",
    "df2=df2.drop('salaryType', axis=1)\n",
    "df2=df2.drop('totalExperience', axis=1)\n",
    "df2=df2.drop('minAnnualSalary', axis=1)\n",
    "df2=df2.drop('maxAnnualSalary', axis=1)\n",
    "df2=df2.drop('minimumExp', axis=1)\n",
    "df2=df2.drop('maximumExp', axis=1)\n",
    "df2=df2.drop('ExlcusionReason', axis=1)\n",
    "df2=df2.drop('degree', axis=1)\n",
    "df2=df2.drop('college', axis=1)\n",
    "df2=df2.drop('grade', axis=1)\n",
    "df2=df2.drop('applieddate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Renaming a column in files4 \n",
    "files4= files4.rename(columns={'jobid':'jobId'})\n",
    "#Making  a jobcandidate column in files4 \n",
    "files4['jobcandidate']=files4['jobId'].astype(str)+'-'+files4['candidateid'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Transforming the files4 dataset\n",
    "df1=files4.pivot_table(index='jobcandidate', columns='assessmentname', values='assessmentscore')\n",
    "#Filling the Nan with 0\n",
    "df1=df1.fillna(0)\n",
    "df1new = pd.DataFrame(df1.to_records())\n",
    "#Merging the 2 dataframes\n",
    "df3=pd.merge(df2,df1new,on='jobcandidate',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making different files for different jobId\n",
    "file101= df3.loc[df3['jobId']==101]\n",
    "file164= df3.loc[df3['jobId']==164]\n",
    "file195= df3.loc[df3['jobId']==195]\n",
    "file199= df3.loc[df3['jobId']==199]\n",
    "file234= df3.loc[df3['jobId']==234]\n",
    "file278= df3.loc[df3['jobId']==278]\n",
    "file280= df3.loc[df3['jobId']==280]\n",
    "file294= df3.loc[df3['jobId']==294]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['jobcandidate', 'jobId', 'Shortlisted', 'assessments_mandatory',\n",
       "       'LocationMatch', 'OpsExperienceMatch', 'SalaryMatch', 'ExperienceMatch',\n",
       "       'OpsSalaryMatch', 'shortqpercentage', 'ExcludeScore', 'locationscore',\n",
       "       'industrymatch', 'functionmatch', 'voiceattempts', 'willingtoRelocate',\n",
       "       'Adventurous', 'Creative', 'Detailed', 'Empathic', 'Energetic',\n",
       "       'Idealistic', 'Independent', 'Learning Orientated', 'Loyal',\n",
       "       'Persuasive', 'Poised', 'Professional', 'Resilient', 'Social',\n",
       "       'Task orientated', 'Team Focused', 'DIRECT', 'Employer general ref 2',\n",
       "       'IIMJOBS', 'LINKEDIN', 'LINKEDIN MSG', 'MONSTER', 'MONSTERDB', 'NAUKRI',\n",
       "       'NAUKRIDB', 'OTHER JOB BOARD 1', 'Other active', 'Other ref 1',\n",
       "       'REFERRAL', 'SHORTLIST DB', 'SOCIAL OTHERS', 'SOCIAL OTHERS 1',\n",
       "       'TIMES JOBS DB', 'WHATSAPP 1', 'Degree', 'JobTitle', 'ratiominexp',\n",
       "       'ratiomaxexp', 'ratiominsalary', 'ratiomaxsalary',\n",
       "       ' Attention to Detail  Powerpoint Error-spotting (SL)',\n",
       "       'Analytical Insights - Taxi Market - Consulting (SL) - Short Version',\n",
       "       'Analytical Insights - Taxi Market - Consulting V2 (SL)',\n",
       "       'Analytical Insights - Taxi Market - Consulting v2 (SL)',\n",
       "       'Assessment Beginning - Please Note (SL)',\n",
       "       'Assessment End - Thank you (SL)',\n",
       "       'Assessment End - Thank you - Dasra (SL) ',\n",
       "       'Business Case: Operational Efficiency - India (SL)',\n",
       "       'Business Case: Profitability (SL)', 'Cognitive Ability - Medium (SL)',\n",
       "       'Data Analysis (SL)', 'Excel (Shortlist) - v1',\n",
       "       'Impact Analyst - Xynteo - Understanding of local markets',\n",
       "       'Market Sizing - India (SL)', 'Project Management - Consulting (SL)',\n",
       "       'Project Management Juggle - Consulting (SL)',\n",
       "       'Project Management  External Stakeholders (SL)',\n",
       "       'Qualitative Market Research (SL)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Columns in the particular file\n",
    "file164.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Selecting the target and train columns\n",
    "target=['Shortlisted']\n",
    "train=[ 'assessments_mandatory',\n",
    "       'LocationMatch', 'OpsExperienceMatch', 'SalaryMatch', 'ExperienceMatch',\n",
    "       'OpsSalaryMatch', 'shortqpercentage', 'ExcludeScore', 'locationscore',\n",
    "       'industrymatch', 'functionmatch', 'voiceattempts', 'willingtoRelocate',\n",
    "       'Adventurous', 'Creative', 'Detailed', 'Empathic', 'Energetic',\n",
    "       'Idealistic', 'Independent', 'Learning Orientated', 'Loyal',\n",
    "       'Persuasive', 'Poised', 'Professional', 'Resilient', 'Social',\n",
    "       'Task orientated', 'Team Focused', 'DIRECT', 'Employer general ref 2',\n",
    "       'IIMJOBS', 'LINKEDIN', 'LINKEDIN MSG', 'MONSTER', 'MONSTERDB', 'NAUKRI',\n",
    "       'NAUKRIDB', 'OTHER JOB BOARD 1', 'Other active', 'Other ref 1',\n",
    "       'REFERRAL', 'SHORTLIST DB', 'SOCIAL OTHERS', 'SOCIAL OTHERS 1',\n",
    "       'TIMES JOBS DB', 'WHATSAPP 1', 'Degree', 'JobTitle', 'ratiominexp',\n",
    "       'ratiomaxexp', 'ratiominsalary', 'ratiomaxsalary',\n",
    "       ' Attention to Detail  Powerpoint Error-spotting (SL)',\n",
    "       'Analytical Insights - Taxi Market - Consulting (SL) - Short Version',\n",
    "       'Analytical Insights - Taxi Market - Consulting V2 (SL)',\n",
    "       'Analytical Insights - Taxi Market - Consulting v2 (SL)',\n",
    "       'Assessment Beginning - Please Note (SL)',\n",
    "       'Assessment End - Thank you (SL)',\n",
    "       'Assessment End - Thank you - Dasra (SL) ',\n",
    "       'Business Case: Operational Efficiency - India (SL)',\n",
    "       'Business Case: Profitability (SL)', 'Cognitive Ability - Medium (SL)',\n",
    "       'Data Analysis (SL)', 'Excel (Shortlist) - v1',\n",
    "       'Impact Analyst - Xynteo - Understanding of local markets',\n",
    "       'Market Sizing - India (SL)', 'Project Management - Consulting (SL)',\n",
    "       'Project Management Juggle - Consulting (SL)',\n",
    "       'Project Management  External Stakeholders (SL)',\n",
    "       'Qualitative Market Research (SL)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Making the training and target columns\n",
    "Y=file278[target]\n",
    "X=file278[train]\n",
    "#Filling the missing rows with 0\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['willingtoRelocate']=X['willingtoRelocate'].astype(int)\n",
    "X['assessments_mandatory']=X['assessments_mandatory'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "#Split the Data in training and testing dataset\n",
    "X_train, X_test, Y_train, Y_test = tts(X,Y, test_size=0.8, random_state = 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed=7\n",
    "scoring='accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.965152 (0.056712)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.930303 (0.087026)\n",
      "KNN: 0.965152 (0.056712)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:437: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART: 0.956818 (0.057100)\n",
      "NB: 0.824242 (0.127750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.965152 (0.056712)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "0.941935483871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.LinearSVC()\n",
    "#fit the train and test data\n",
    "clf.fit(X_train, Y_train)\n",
    "print (clf)\n",
    "#checking the accuracy of model\n",
    "print(clf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948387096774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ashwani\\anaconda3\\envs\\neuralnets\\lib\\site-packages\\sklearn\\utils\\validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_A = LogisticRegression(random_state = 42)\n",
    "\n",
    "clf_A.fit(X_train, Y_train)\n",
    "print(clf_A.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-c05039ddc764>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclf_C\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m120\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclf_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "clf_C = xgb.XGBClassifier(seed = 120)\n",
    "clf_C.fit(X_train, Y_train)\n",
    "print(clf_C.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = clf.fit(X_train, Y_train).predict(X_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(Y_test, Y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=target,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=target, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file278['Shortlisted'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
